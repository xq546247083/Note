# 面试题

## C#程序内存构成

    C#程序的内存架构由多个部分组成，主要依赖于公共语言运行时（CLR）的管理机制。以下是详细的分点总结：
    1、栈（Stack）
        线程私有：每个线程拥有独立的栈空间，默认大小通常为1MB（可配置）。
        存储内容：
            - 局部值类型变量（未闭包捕获时）。
            - 方法调用的参数、返回地址及上下文信息。
            - 值类型的对象本身，引用类型的引用地址（指针），静态对象的引用地址（指针），常量对象的引用地址（指针）等
        特点：
            - 自动管理（后进先出），方法结束时栈帧弹出。
            - 栈溢出（如深度递归）会导致`StackOverflowException`，通常无法恢复。
    2、加载堆，使用!eeheap -loader可以查看
        主要是供CLR内部使用，作为承载程序的元数据。
        HighFrequencyHeap
            存放CLR高频使用
            之间的继承关系，调用接口的方法和虚方法，都需要访问MethodTable
        LowFrequencyHeap
            存放CLR低频使用的内部数据，比如EEClass,ClassLoader.
            GC信息与异常处理表，它们都只在发生时才访问，因此访问频率不高。
        StringLiteralMap
            字符串驻留池:https://www.cnblogs.com/lmy5215006/p/18494483
            字符串对象本身存储在FOH堆中,String Literal Map只是一个索引
        StubHeap
            函数入口的代码堆
        CodeHeap
            JIT编译代码使用的内部堆，比如生成IL。
        VirtualCallStubHeap
            虚方法调用的内部堆
    3、托管堆（Managed Heap），使用!eeheap -gc可以查看
        CLR管理：由垃圾回收器（GC）自动回收内存。
        存储内容：
            - 引用类型实例（如类对象）。
            - 装箱后的值类型。
            - 闭包捕获的变量（提升到堆的生成类中）。
        1、SOH(small object heap)
            1、这个是分代管理
                Gen 0：新对象，GC最频繁。
                Gen 1：存活过Gen 0回收的对象。
                Gen 2：长期存活的对象。
            2、GC升代,不是copy对象从0代到1代。而是移动代的边界。每次GC触发时，代边界指针会在多个“地址段”上迁移，通过这种逻辑操作，优化性能。
            3、每代的清理算法，大致：0代为标记复制，1、2代为标记清理、标记整理。
        2、LOH(large object heap)
            - 存储对象大小≥85KB（如大数组）。
            - GC处理频率低，不压缩（可能导致碎片）。
        3、POH
            固定对象专属的堆，比如非托管线程访问托管对象，就需要把对象固定起来，避免被GC回收造成非托管代码的访问违例.
        4、FOH（Frozen object heap,又叫NoneGCHeap，冻结堆)
            NET8推出来的一个新堆，用来存放永远不会被GC管理的永生对象，比如string 字面量（literal）。
        5、堆是逻辑概念，物理上由多个内存段(Heap Seg-ment)构成。
    4、非托管堆（Unmanaged Heap）
        手动管理：通过`unsafe`代码、`IntPtr`或调用系统API（如`Marshal.AllocHGlobal`）分配。
        典型场景：
            - 与非托管库交互（如文件句柄、数据库连接）。
        风险：需显式释放（如`IDisposable`接口、`using`语句），否则导致内存泄漏。

        高频堆（High-Frequency Heap/Loader Heap）
        存储内容：
            - 类型元数据、方法表、静态变量。
            - 常量（编译时确定的值）。
        特点：
            - 生命周期与应用程序域（AppDomain）绑定，不会被GC回收。
    5、其他内存区域
        代码段：JIT编译后的本地代码。
        应用程序域（AppDomain）：逻辑隔离单元，静态变量在各自AppDomain独立。
    6、特殊场景
        字符串驻留（Interning）：`string`字面量存入进程级的池，避免重复。
        结构体（Struct）：
            - 默认栈分配，若嵌入类中则存于堆。
            - 显式内存布局可通过`StructLayout`定制（如与非托管代码交互）。
    7、内存管理注意事项
        GC优化：短生命周期对象应避免晋升到Gen 2。
        内存泄漏：
            - 静态集合长期持有对象引用。
            - 未释放非托管资源（需实现`IDisposable`）。
        性能权衡：值类型减少堆分配，但需避免过度装箱。

## NetFramework升级NetCore 8的经验

    1、VS自带的项目升级
    2、基础框架修改为netstandard2.0
    3、处理包引用、ASPNetCore不兼容的地方、数据库不兼容的地方
    4、优化跨平台的发包方式

##  list、hashset 

    当然，`List` 和 `HashSet` 是常见的数据结构，它们在不同的编程语言中都有实现。以下是对它们的详细介绍，包括它们的原理和特点。
    1. List
        `List` 是一种线性数据结构，用于存储有序的元素集合。它可以动态扩展或缩小，以适应元素数量的变化。
        特点
        - 有序性：元素按照插入顺序排列。
        - 允许重复：可以存储重复的元素。
        - 支持索引访问：可以通过索引快速访问或修改元素。
        - 动态扩展：可以根据需要自动调整大小。
        实现原理
        - 基于数组的实现（如 ArrayList）：
        - 内部使用一个动态数组来存储元素。
        - 当数组容量不足时，会创建一个更大的数组，并将原有元素复制到新数组中。
        - 插入和删除操作在数组中间位置时效率较低，因为需要移动大量元素。
        - 基于链表的实现（如 LinkedList）：
        - 内部使用双向链表来存储元素。
        - 每个节点包含一个元素和两个指针（指向前后节点）。
        - 插入和删除操作在链表中间位置时效率较高，因为只需调整指针即可。
        适用场景
        - ArrayList：适合需要频繁随机访问的场景，如需要按索引快速查找或修改元素。
        - LinkedList：适合需要频繁插入和删除的场景，如频繁在列表中间插入或删除元素。
    1. HashSet
        `HashSet` 是一种基于哈希表的集合数据结构，用于存储无序的、唯一的元素集合。
        特点
        - 无序性：元素没有固定的顺序。
        - 唯一性：不允许存储重复的元素。
        - 快速查找：通过哈希函数实现高效的查找、插入和删除操作。
        实现原理
        - 基于哈希表：
        - 内部使用一个哈希表来存储元素。
        - 每个元素通过哈希函数计算出一个哈希值，该哈希值决定了元素在哈希表中的存储位置（称为“桶”）。
        - 如果两个元素的哈希值相同（称为“哈希冲突”），通常使用链表或开放寻址法来解决冲突。
        - 哈希冲突解决方法：
        - 链表法：每个桶存储一个链表，冲突的元素被存储在同一个链表中。
        - 开放寻址法：当发生冲突时，按照某种探测规则（如线性探测）寻找下一个可用的桶。
        适用场景
        - 需要快速判断某个元素是否存在。
        - 需要存储唯一值的集合。
        - 不关心元素的顺序。
    总结
    - List：适合需要有序存储和频繁随机访问的场景。
    - HashSet：适合需要快速查找和存储唯一值的场景。

## 如何维护线程安全？ concurrentbag 类做法是怎么样的？

    1. 线程安全的维护
        在多线程编程中，维护线程安全是确保数据一致性的重要任务。以下是常见的线程安全维护方法：
        - 锁机制：通过 `lock` 或 `Monitor` 确保同一时间只有一个线程访问共享资源。
        - 无锁编程：使用原子操作（如 `Interlocked`）避免锁的开销。
        - 线程本地存储：每个线程独立操作自己的数据，减少竞争。
        - 不可变性：使用不可变对象确保线程安全。
        - 线程安全集合：使用专门设计的线程安全集合类（如 `ConcurrentBag`）。
    2. `ConcurrentBag` 的实现原理
        `ConcurrentBag` 是 .NET 提供的一种线程安全的集合类，专为多线程场景设计。它的主要特点和实现原理如下：
        - 无序性：`ConcurrentBag` 不保证元素的插入顺序，`TryTake` 方法可能返回任意元素。
        - 线程安全：通过线程本地存储（Thread-Local Storage）实现高效并发。每个线程维护自己的局部队列，减少跨线程竞争。
        - 工作窃取：当一个线程的局部队列为空时，它可以从其他线程的队列中“窃取”任务，提高 CPU 利用率。
        - 无锁设计：内部使用无锁技术（如原子操作）确保高性能。
       1. 典型应用场景
          - 工作窃取模式：多个线程共享任务池，空闲线程从其他线程的任务队列中窃取任务。
          - 临时数据收集：并行计算中，各线程生成的中间结果可以安全地添加到 `ConcurrentBag` 中。
       2. 注意事项
          - 无序性：`ConcurrentBag` 不保证元素顺序，适合不需要顺序的场景。
          - 性能权衡：在频繁跨线程操作的场景中，可能不如 `ConcurrentQueue` 或 `ConcurrentStack` 高效。
          - 空集合处理：`TryTake` 可能失败，需结合循环或超时机制。

## async和await的趣事

    该类用来启动WebSocket客户端，启动时，第一个为和服务循环检测，保持链接，第二个为循环接受消息，在没有连接的时候，跳过本次接受。以前用的Thread，升级到信创后，修改为async的方式，启动上面的2个异步操作。但是，当服务不在线的时候，客户端连接失败，接受消息方法中，先会判断连接是否打开，没有打开，直接进行下一个循环(因为没有进入await client.ReceiveAsync()，堆栈没有返回)，导致启动时，程序卡主。

## async/await

    本质是状态机。
    异步方法的生命周期可以分为以下几个阶段：
        1、初始化：创建状态机实例，初始化状态和任务构建器。
        2、开始执行：调用 Start 方法开始执行异步方法。
        3、执行方法体：在 MoveNext 方法中，根据当前状态执行相应的代码。
        4、遇到 await：检查任务是否完成，如果未完成则注册回调并暂停方法执行。
        5、任务完成：回调被触发，重新调用 MoveNext 方法，恢复异步方法的执行。
        6、方法完成：所有异步操作完成，设置任务的结果或异常。
    这导致await看似是阻塞，实则是回调。

## valuetask

    1、值类型。
    2、很多限制，最好只是在await立等结果的地方使用。
    3、一般不使用，在大量的循环中为了性能可能使用。(Task为引用类型，会创建大量的对象在堆上，导致GC压力)

## 什么是 async io,在.net 上表现形式是什么

    什么是异步IO？
        异步IO（Asynchronous I/O）是一种用于优化I/O操作的技术，它允许程序在等待I/O操作完成时不阻塞线程，从而提高系统的响应能力和吞吐量。与传统的同步I/O操作不同，异步I/O操作不会阻塞调用线程，而是在线程等待I/O操作完成时释放线程资源，让线程去执行其他任务。当I/O操作完成时，系统会通知程序，程序可以继续处理结果。
    在.NET上的表现形式
        在.NET中，异步IO主要通过async和await关键字来实现，这些关键字是C#异步编程的核心。从.NET Framework 4.5开始，I/O类型包括了异步方法，以简化异步操作。这些异步方法在其名称中包括Async，例如ReadAsync、WriteAsync、CopyToAsync、FlushAsync、ReadLineAsync和ReadToEndAsync等。

## iocp、epoll

    epoll
        linux使用，通知你来处理任务，回调状态。
    iocp
        win使用，任务完成后，通知你来接受，回调任务。

## 如何将一段内存数据转换为 struct

    Marshal

## GC

    1、模式
        一、工作站模式
            垃圾回收的频率较高，但每次回收的停顿时间较短。
            垃圾回收直接在触发回收的用户线程上执行，与其他用户线程竞争 CPU 时间。
            只分配一个 GC 堆，因此内存分配较少
        二、 服务器模式
            垃圾回收的频率较低，减少停顿时间。
            为每个 CPU 核心分配一个独立的 GC 堆和专用线程，提高吞吐量和性能。
            通常分配更大的内存分段，适合多核心系统
    2、子模式
        后台模式（Background GC）：
            使用专用线程回收第 2 代对象，回收时不会挂起其他线程。
            适用于需要减少停顿时间的场景。
        非并发模式（Non-Concurrent GC）：
            垃圾回收时会挂起所有其他线程，适用于对停顿时间要求不高的场景
    3、抑制GC回收
        GC.TryStartNoGCRegion
    4、查看GC的数量
        Windebug
    5、GC堆的种类
        0、1、2代，以及大对象堆
        分类主要是为了快速回收内存，降低卡顿。生命周期短的对象，在0代被快速回收，生命周期长的进入1、2代，降低0代的数量，增加回收效率。

## 终结器

    终结器（Finalizer）是一种在垃圾回收过程中自动调用的方法，用于执行清理工作。它允许开发者在对象被垃圾回收器回收之前，释放系统资源、关闭文件、断开数据库连接等。
    使用场景
        终结器主要用于释放非托管资源，如文件句柄、数据库连接等。这些资源需要显式的清理，而垃圾回收器不知道如何处理它们。
    使用问题
        执行时间不确定：终结器的执行时间由垃圾回收器决定，无法保证及时性。这可能导致资源释放延迟。
        不能显式调用：终结器只能由垃圾回收器调用，开发者无法控制其执行时间。
        未捕获异常：终结器中抛出的未捕获异常会被忽略，这可能导致程序状态不一致。
        性能开销：终结器的使用会增加垃圾回收的复杂性，降低回收效率。
        安全问题：终结器可能受到终结器攻击，导致恶意子类记录部分构造对象的引用，从而引发安全问题。
    替代方案
        确定性终结：通过实现 IDisposable 接口，显式调用 Dispose 方法来释放资源。
        try-finally 或 try-with-resources：确保资源在异常情况下也能被正确释放。

## 泛型

    泛型的优点
        1、值类型装箱会额外占用内存
        2、装箱/拆箱会消耗额外的CPU
        3、代码复用，简单
    
    泛型的缺点
        1、生成的代码爆炸
        2、优化代码爆炸（按照目前的优化，如果不是大量使用结构体，不会出现生成的代码爆炸）
            1、相同类型实参，共用一套方法
            2、引用类型实参，共用一套方法

## 委托

    1、本质是封装了c++的函数指针，是编译时确保类型安全。
    2、多播是因为存储了invocationList。

## 反射

    1、反射的本质就是“操作元数据”
    2、元数据：存储在dll中的一个信息数据库，记录了这个assembled中有哪些方法，哪些类，哪些属性等等信息，通过ILSpy可以看到由各种Table组成的信息。
    3、反射到底慢在哪？
        动态解析
            从上面可知道，反射作为后期绑定，在runtime中要根据metadata查询出信息，严重依赖字符串匹配，这本身就增加了额外的操作
        动态调用
            使用反射调用方法时，先要将参数打包成数组，再解包到线程栈上。又是额外操作。
        无法在编译时优化
            反射是动态的临时调用，JIT无法优化。只能根据代码一步一步执行。
        额外的安全检查
            调用方法时，进行额外的安全性检查，检查参数类型是否正确。这也会增加一定的开销
        缓存易失效
            反射如果参数发生变化，那么缓存的汇编就会失效。又需要重新查找与解析。
    4、Emit是.NET提供的一种动态生成和编译代码的技术。通过 Emit，我们可以动态生成一个新的方法，这个方法可以直接访问修改私有成员。
    5、Expression是.NET提供的一种表达式树的技术。通过 Expression，我们可以创建一个表达式树，然后编译这个表达式树，生成一个可以访问修改私有成员的方法。
    6、UnsafeAccessorAttribute是.Net 8中引入了新特性。使用该特性，来提供对私有字段的快速修改。
        这个速度很快，原因是：对于C#来说，私有类型是OOP语言的定义。它定义了什么是私有类型，它的行为是什么。但对于程序本身来说，代码和数据都只是一段内存，实际上你的指针想访问哪就访问哪。哪管你什么私有类型。换一个指向地址不就得了。因此CLR开放了这么一个口子，利用外部访问直接操作内存。
        static void New()
        {
            var person = new Person();
            AccessAgeField(person) = 100;
            var age = AccessAgeField(person);
        }
        [UnsafeAccessor(UnsafeAccessorKind.Field, Name = "_age")]
        static extern ref int AccessAgeField(Person counter);

## 属性

    Attribute对象的很多方法实现是依赖反射。在使用中，使用Dictionary缓存结果集。避免过多调用反射造成的性能问题。

## 线程

    1、Windows下线程的数据结构
        每个线程都有以下要素，这是创建线程无法避免的开销。
        线程内核对象(Thread Kernel Object)
            OS中创建的每一个线程都会分配数据结构来承载描述信息
            Windows会给每一个 Thread 分配一个_ETHREAD的内存结构，用来记录当前线程的状态，其中就包括了线程上下文(Thread Context)
        线程环境块(Thread Environment Block, TEB)
          TEB是在用户态中分配的内存块，主要包括线程的Exception，Local Storage等信息
        用户态线程栈(User-Mode Stack)
            我们常说的栈空间就是指的这里
        内核态线程栈(Kernel-Mode Stack)
            处于安全隔离考虑，在内核态中复制了一个同样的栈空间。用来处理用户态访问内核态的代码。
    2、线程上下文切换的本质
        上下文切换的本质就是，备份被切换线程寄存器的值，到该线程的上下文中。再从切换后的线程中，读取上下文到寄存器中。
    3、ThreadLocal
        TLS是基于C++做的封装，TLS中存储了一个ThreadLocalInfo对象。可以借助它与Thread的关联，来得知存储在托管堆中的线程本地变量。
    4、AsyncLocal
        C#中每一个线程都会绑定一个ExecutionContext,可以使用Thread.CurrentThread.ExecutionContext来查看。理想情况下，当一个线程使用另一个线程执行任务时，前者的执行ExecutionContext会被copy到后者中来。这个过程被称为上下文流动因此，AsyncLocal能够执行成功秘诀就在于，当线程切换的时候，线程1所存储AsyncTLS流动到了到了线程2。因此线程2能够读取到线程1的值。

## 线程池

    1、线程池执行队列的类型
        全局队列
        低优先级队列
        高优先级队列
        线程本地队列
    2、线程执行优先级
        当线程池Dequeue时，会优先检查本地队列(LIFO)，如果为空就查询高优先级队列，再检查全局队列，再检查低优先级队列。如果检查完低优先级队列还是为空，那么它会"窃取"其它线程的本地队列。需要注意一点的是，当窃取其它线程的任务时，它会使用FIFO顺序来访问，被窃取的线程还是不变使用LIFO。这样一个从头部读取(被窃取的线程)，一个从尾部读取(窃取的线程)。无需同步锁，减少冲突。
    3、本地队列线程的优点
        减少线程竞争，尽量使相同的代码使用一个线程，这样会减少锁等待的概率。
        提高缓存利用率，减少切换线程的缓存数据，因为有些共用的数据。
        工作窃取机制的基础，有本地队列，才有窃取这个说法，防止空线程。
        降低上下文切换成本。
    4、Task
        Task的底层实现主要取决于TaskSchedule，一般来说，除了UI线程外，默认是调度到线程池，也就是本质也是线程池。
    5、Task对线程池的优化
        既然Task的底层是使用ThreadPool,而线程池注入速度是比较慢的。所以当使用Task.Result时，底层会调用InternalWaitCore(),如果Task还未完成,会调用ThreadPool.NotifyThreadBlocked()来通知ThreadPool当前线程已经被阻塞，必须马上注入一个新线程来代替被阻塞的线程。相对每500ms来轮询注入线程，该方式采用事件驱动，注入线程池的速度会更快。

## Async(异步)

    1、异步，适用于"IO密集型"的场景,它可以避免因为线程等待IO形成的线程饥饿，从而造成程序吞吐量的降低。他可以是一个线程实现。IOCP则为异步。
    2、多线程，适用于"CPU密集型",主要是为了更多的利用多核CPU来同时执行逻辑。将一个大任务分而治之，提高完成速度，进而提高程序的并发能力。
    3、异步操作的核心:IO完成端口(IO Completion Port，简称IOCP)
        IO完成端口（IO Completion Port）是Windows操作系统的一个内核对象，专门用来解决异步IO的问题，C#中所有异步操作都依赖此端口。其本质是一个发布订阅模式的队列，CLR在初始化时，创建一个IO Completion Port完成与硬件设备的绑定，使得硬件的驱动程序知道将IRP送到哪里去。
    4、异步的本质是状态机，状态机的核心是：MoveNext函数，一个Task最少要被调用两次MoveNext,第一次调用是主动触发初始化状态机，第二次调用是回调函数再次执行状态机。
    5、Aysnc的异常处理
        当异步操作发生异常时，IO Completion Port会告诉程序，异步操作已经完成，但存在一个错误。不会跟常规异常一样直接从内核态抛出一个异常。因此ThreadPool调用SetException存储起来。当你调用await/GetResult() 或者直接try catch时才会真正的抛出异常。如果都有没有捕获，则异常会被吃掉，导致无法分析错误问题。

## Lock

    1、用户态锁（代表是自旋锁，也有互斥锁）
        优点：
            因为线程一直在自旋，所以没有现成切换，所以通常性能较高，不需要进行用户态与内核态的切换，避免了切换带来的额外开销，如上下文保存与恢复等。例如在无竞争的情况下，用户态的自旋锁和互斥锁都可以快速地获取和释放锁，执行时间相对较短.
        缺点：
            在高并发竞争激烈的情况下，如果线程长时间获取不到锁，自旋锁会导致 CPU 空转浪费资源，而互斥锁的等待队列管理等也会在用户态消耗一定的 CPU 时间.
    2、内核态锁（互斥锁）
        优点：
            内核态锁由操作系统内核管理和调度，当锁被释放时，内核可以及时地唤醒等待的线程，适用于复杂的同步场景和长时间等待的情况.
        缺点：
            由于涉及到用户态与内核态的切换，开销较大，这在锁的竞争不激烈或者临界区执行时间较短时，会对性能产生较大的影响。会有两次线程上下文切换的成本：
                1、当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；
                2、接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。
    3、原子操作适用场景
        一、针对可以重试的情况，如后台任务，如果正在运行，则下一次尝试。
        二、用户点击，可以直接返回，正在运行。
    4、读写锁（ReaderWriterSlim）
        内存中的数据读写
    5、Lock
        同时只能有一个线程访问的情况。
    6、读写锁、Lock
        都是混合锁，其内部由两部分构成，也分别对应不同场景下的用户态与内核态实现。
            自旋锁(Thinlock)：CoreCLR利用Thinlock机制来实现轻量级自旋。
            内核锁(AwareLock):当自旋无效的情况下，会退化为awarelock锁，并用SyncBlock来维护锁信息。
        锁先使用用户态锁自旋一定次数，如果获取不到锁。再转换成内核态锁。从而降低CPU消耗。
    7、悲观锁和乐观锁
        上面的都是悲观锁
        乐观锁：
            就是不加锁，先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。
    8、锁问题
        1、死锁 你要我的锁，我要你的锁。
        2、孤儿锁 因为异常等情况，没有释放锁。

## 异常

    1、异常的分类
        用户异常
        硬件异常
    2、异常的实现
        一、记录异常处理表
            一旦方法中有try-catch语句块时，JIT会将try-catch的适用范围记录下来，并整理成异常处理表(Execption Handling Table , EH Table)
        二、捕获异常并抛出异常的位置
            .NET9之前进入内核态利用SEH机制捕获并定位异常，.NET9之后在用户态的异常在托管层自行捕获。
        三、通过线程栈空间获取异常调用栈
            线程的栈空间维护了整个调用栈，扫描整个栈空间即可获取。
        四、获取元数据的异常处理表
            当异常发生时，Runtime会枚举EH Table，找出并调用对应的catch块与finally块。

## C#源码到汇编的过程

    一、C#源码被Roslyn编译器编译成DLL，DLL中包含了MetaData与IL Code。
    二、由加载器（ClassLoader）根据MetaData构建出类型系统的数据结构。
    三、再由JIT编译器根据IL Code，懒加载式的生成汇编等。

## 常用集合的注意事项
    
    1、List.Insert(0, item) 的坑
        List基于数组实现，数组在内存中是连续存储的。当使用 Insert(0, item) 在列表开头插入元素时，列表中现有的所有元素都需要向后移动一个位置，以便为新元素腾出空间。这意味着插入操作的时间复杂度为O(n) ，其中n是列表中现有元素的数量。元素数量越多，移动元素所花费的时间就越长，性能也就越低。
    2、HashSet/Dictionary
        Dictionary<TKey, TValue> 的底层结构主要由以下几个部分组成：
        桶（Bucket）数组：
            这是一个一维数组，数组的每个元素称为一个桶。桶数组的大小是 Dictionary 的容量，初始容量通常是一个较小的质数，后续会根据元素数量的增加而动态调整。
        条目（Entry）数组：每个桶对应一个或多个条目，条目是一个结构体，包含三个重要的字段：
            *. int hashCode：键的哈希码，用于确定键在桶数组中的位置。
            *. int next：指向下一个条目的索引，用于处理哈希冲突。如果该值为 -1，表示这是该桶中的最后一个条目。
            *. TKey key：存储的键。
            *. TValue value：存储的值。
    3、ConcurrentDictionary
        ConcurrentDictionary<TKey, TValue> 的底层核心是由多个分段（Segment）组成，每个分段本质上是一个小型的哈希表，并且每个分段都有自己独立的锁。这种设计将整个字典划分为多个部分，不同线程可以同时访问不同的分段，从而减少锁的竞争，提高并发性能。
    4、ConcurrentQueue
        一、ConcurrentQueue 底层主要基于链表（Linked List）数据结构实现，链表是一种动态的数据结构，由一系列节点（ConcurrentQueueSegment）组成，每个节点包含一个数据元素和一个指向下一个节点的引用。为了保证线程安全，ConcurrentQueue 在链表的基础上使用了无锁（Lock - Free）算法，主要借助原子操作（如 Interlocked 类提供的方法）来避免传统锁带来的性能开销和潜在的死锁问题。
        二、Count操作：不要高频次调用Count属性，因为内部调用逻辑非常复杂，需要遍历每一个Segment的head,tail之间的差值，动态计算出最终的大小，且还有加锁操作，消耗不低。

## AspNetCore管道

    ASP.NET Core 的管道是一系列按顺序调用的请求委托（middleware），用于处理 HTTP 请求和响应。每个委托可以执行一些操作，然后将请求传递给管道中的下一个委托。

## Kestrel

    Kestrel 作为一个高性能的 Web 服务器，使用了许多性能优化技术，如异步 I/O、零拷贝传输、管道（System.IO.Pipelines）等：
        异步 I/O：Kestrel 是一个异步的事件驱动服务器，使用 Task 和 async/await 来处理大量并发连接。
        System.IO.Pipelines：这是一个高效的流处理 API，Kestrel 使用它来减少内存分配和提高吞吐量。
            一、缓冲池的使用：借助Span<byte>来避免重复内存分配，让内存使用更加高效。
            二、缓冲区扩展：当缓冲区数据不足时，通过扩展而不是重新分配，提升了性能。
        连接池：Kestrel 使用连接池来优化大量连接的处理，减少连接创建和销毁的开销。
        基于 .NET Core 的运行时优化：利用 Span<T>、ref struct、ValueTask 等特性减少堆分配，提升内存效率。
        低开销的垃圾回收（GC）：通过对象池（ArrayPool<T>）和 IDisposable 接口主动释放资源，降低 Gen 0 GC 频率。
        中间件管道优化：请求处理管道（Middleware Pipeline）通过 RequestDelegate 链式调用，避免反射和动态分发，提升执行速度。

## Span、Memory

    memory是span的引用版本。他们主要是可以直接访问内存，减少了内存复制的频率。
    优点：
        减少了垃圾回收器的分配次数，还能减少数据副本的数量，为同时处理多个缓冲区提供更有效的方法。
        允许你编写高性能代码。例如，如果有一大块内存需要分割成小块，可以使用 Span 作为原始内存的视图。这样就可以直接访问原始缓冲区中的字节，而无需复制。
        允许直接访问内存而无需复制，这在使用本地库或与其他语言互操作时尤其有用。
        在对性能要求较高的紧凑循环中（如密码学或网络数据包检查），可以省去边界检查。
        可以消除与 List 等通用集合相关的装箱和拆箱成本。

## efcore如何从数据变成对象

    1、第一次查询数据会创建映射关系，并缓存。
    2、根据映射关系，反射对象和赋值。

## 装箱和拆箱

    只有值类型才有装箱、拆箱两个状态，而引用类型一直都在箱子里。
        装箱：把箱子存放了值类型字段的引用对象实例，箱子存储在托管堆上。
        拆箱：把值类型取到栈上。

## 字符串

    1、字符串特性：不可变性，驻留性。
    3、字符串字面量的引用存放在StringLiteralMap，值存在在FOH,所以是引用类型。代表着字符串字面量不会被回收，其他的会。
        怎么是否存放在StringLiteralMap：String.IsInterned(string str);
    3、StringBuilder
        底层是字节数组，拼接时，填充字节即可，不需要像字符串拼接需要每次创建新的字符串。扩容时，创建一个更大的数组，拷贝数据到新的数组，原数组被放弃。
    
## 继承本质、override、new

    每个类都维护了一个方法表，按照就近原则执行。
        方法表加载时父类在前子类在后，首先加载的是固定的4个来自System.Object的虚方法：ToString, Equals, GetHashCode, and Finalize；
        然后加载父类A的虚方法；
        加载自己的方法；
        最后是构造方法：静态构造函数.cctor()，对象构造函数.ctor()；
    不同的类型指针在虚拟方法表中有不同的附加信息作为标志来区别其访问的地址区域，称为offset。
    
    override本质是重写了继承的方法，所以不管现在类型是子类还是基类，都会调用到重写的方法。
    new本质是添加了一个新的方法，这个方法在子类的地址区域。如果类型是子类，根据offset，按照就近原则，子类的new方法被会执行。如果类型是父类，则执行父类的方法。

## 数据库索引的总结

    创建索引的的字段尽量小，最好是数值，比如整形int等；
    对于频繁修改的字段，尽量不要创建索引，维护索引的成本很高，而且更容易产生索引碎片；
    定期的索引维护，如索引碎片的修复等；
    不要建立或维护不必要的重复索引，会增加修改数据（新增、修改、删除数据）的成本；
    使用唯一性高的字段创建索引，切不可在性别这样的低唯一性的字段上创建索引；
    在SQL语句中，尽量不要在Where条件中使用函数、运算符或表达式计算，会造成索引无法正常使用；
    应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描；
    应尽量避免在 where 子句中使用!=或<>操作符，否则将导致引擎放弃使用索引而进行全表扫描；

## redis的几个常见问题

    缓存穿透
        缓存穿透是指查询一个不存在的数据，由于缓存是不命中时被动写的，如果从DB查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到DB去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了。
        缓存空值。
    缓存雪崩
        缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重挂掉。
        在原有的失效时间基础上增加一个随机值，使得过期时间分散一些。这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
    缓存击穿
        缓存击穿：大量的请求同时查询一个 key 时，此时这个 key 正好失效了，就会导致大量的请求都落到数据库。缓存击穿是查询缓存中失效的 key，而缓存穿透是查询不存在的 key。
        1、加互斥锁。2、标记当前查询次数，查询成功置为0，如果超过一定次数，直接返回系统繁忙。
    缓存预热
        缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！
    缓存降级
        当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

## c# 12、13中的新语法

    1、展开运算符
        int[] item0 = [88, 2, 3];
        int[] item1 = [22, 5, 6];
        int[] item2 = [7, 99, 9];
        int[] single = [.. item0, .. item1, .. item2];
    2、锁的优化
        private System.Threading.Lock _newLock = new System.Threading.Lock();
        using (_newLock.EnterScope())
        {
            //  作用域自动释放（推荐写法）
        }

## 提供CPU数据缓存命中率

    1、当 CPU 访问数据时，如果 CPU Cache 没有缓存该数据，则会从内存读取数据，但是并不是只读一个数据，而是一次性读取一块一块的数据存放到 CPU Cache 中，之后才会被 CPU 读取。我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升；
    2、对于多核 CPU 系统，线程可能在不同 CPU 核心来回切换，这样各个核心的缓存命中率就会受到影响，于是要想提高线程的缓存命中率，可以考虑把线程绑定 CPU 到某一个 CPU 核心。

## 负数和小数

    1、负数
        通过补码的方式表示，-1为1的取反。这样直接相加才会是0。
        1为：00000000000000000000000000000001
        -1为：11111111111111111111111111111110
        他们的第一位为符号位，0为正数，1为负数。
    2、小数是通过乘2取整法
        0.625在二进制中是0.101，其中第一位为是0.5，第二位是0，第三位是0.125。

## 虚拟内存

    目的：
        1、为了在多进程环境下，使得进程之间的物理内存地址不受影响，物理内相互隔离，于是操作系统就为每个进程独立分配一套虚拟地址空间，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。
        2、每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过内存交换技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。
    虚拟内存空间分布：
        因为是虚拟空间是虚拟的，所以地址空间直接是满的。32位是4个GB。64位因为太大了，所以只用了256TB。
        内存空间从小到大依次是：
            一、用户态空间：
                在32位上为3G，在64位上为128T
                1、保留区
                    目前没有用
                2、代码段
                    从程序的二进制文件中直接加载进内存中的，所以大小是固定的
                3、数据段
                    从程序的二进制文件中直接加载进内存中的，指定了初始值的全局变量和静态变量，所以大小是固定的
                4、BSS段
                    从程序的二进制文件中直接加载进内存中的，没有指定初始值的全局变量和静态变量，所以大小是固定的
                5、堆
                    动态扩展大小，地址是从小到大申请。
                6、文件映射和匿名映射区
                7、栈
                    动态扩展大小,在用户态空间的最大位置，所以地址是从大到小申请。
            二、内核空间
                在32位上为1G，在64位上为128T，在虚拟空间的最大位置。
    实现：
        1、那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。
        2、那么对于虚拟地址与物理地址的映射关系，可以有分段和分页的方式，同时两者结合都是可以的。

## 为什么操作系统添加了虚拟内存

    第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。
    第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。
    第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

## 内存不够了操作系统会怎么办

    文件页的回收：
        对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。
    匿名页的回收：
        如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。
    如果还是不够，则直接出发OOM异常。

## 在4GB的机器上申请8GB的内存会怎么样

    x86进程
        因为进程理论上最大能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。
    x64进程
    因为进程理论上最大能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：
        如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）；
        如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行；

## linux、MySQL的数据缓存实现

    LRU算法
        一般是用「链表」作为数据结构来实现的，链表头部的数据是最近使用的，而链表末尾的数据是最久没被使用的。那么，当空间不够了，就淘汰最久没被使用的节点，也就是链表末尾的数据，从而腾出内存空间。
    预读机制:
        1、应用程序只想读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。
        2、操作系统出于空间局部性原理（靠近当前被访问数据的数据，在未来很大概率会被访问到），会选择将磁盘块 offset [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) 都加载到内存，于是额外在内存中申请了 3 个 page。应用程序利用 read 系统调动读取 4KB 数据，实际上内核使用预读机制（ReadaHead） 机制完成了 16KB 数据的读取，也就是通过一次磁盘顺序读将多个 Page 数据装入 Page Cache。这样下次读取 4KB 数据后面的数据的时候，就不用从磁盘读取了，直接在 Page Cache 即可命中数据。因此，预读机制带来的好处就是减少了 磁盘 I/O 次数，提高系统磁盘 I/O 吞吐量。MySQL Innodb 存储引擎的 Buffer Pool 也有类似的预读机制，MySQL 从磁盘加载页时，会提前把它相邻的页一并加载进来，目的是为了减少磁盘 IO。
    预读失效：
        这些被提前加载进来的页，并没有被访问，相当于这个预读工作是白做了，这个就是预读失效。如果使用传统的 LRU 算法，就会把「预读页」放到 LRU 链表头部，而当内存空间不够的时候，还需要把末尾的页淘汰掉。如果这些「预读页」如果一直不会被访问到，就会出现一个很奇怪的问题，不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是热点数据，这样就大大降低了缓存命中率。
    linux 和 MySQL 对传统的 LRU 链表做了改进：
        Linux 操作系统实现两个了 LRU 链表：活跃 LRU 链表（active list）和非活跃 LRU 链表（inactive list）。
        MySQL Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：young 区域 和 old 区域。
    如果还是使用「只要数据被访问一次，就将数据加入到活跃 LRU 链表头部（或者 young 区域）」这种方式的话，那么还存在缓存污染的问题。为了避免「缓存污染」造成的影响，Linux 操作系统和 MySQL Innodb 存储引擎分别提高了升级为热点数据的门槛：
        1、Linux 操作系统：
            在内存页被访问第二次的时候，才将页从 inactive list 升级到 active list 里。
        2、MySQL Innodb：
            在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要进行停留在 old 区域的时间判断：
            如果第二次的访问时间与第一次访问的时间在 1 秒内（默认值），那么该页就不会被从 old 区域升级到 young 区域；
            如果第二次的访问时间与第一次访问的时间超过 1 秒，那么该页就会从 old 区域升级到 young 区域；

## 进程间通信

    管道
        管道，就是内核里面的一串缓存。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据，读取后，写入端才返回。所以效率很低。
    消息队列
        优化管道版本，消息队列是保存在内核中的消息链表，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。比如：A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。
    共享内存
        共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。
    信号量
        信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。
    本地Socket
        本地 socket 被用于在同一台主机上进程间通信的场景：
            本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议；
            本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现；
        对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。
        对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。
        本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。

## 零拷贝

    零拷贝不是真正的指零次拷贝，而是不经过用户态的内存拷贝（也就是0次的用户态拷贝）。故而，零拷贝技术是不允许进程对文件内容作进一步的加工的，比如压缩数据再发。
    DMA(Dicrect Memory Access):
        在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情。
    正常的一次文件发送：
        1、线程发出读取文件指令，切换到内核态。
        2、DMA读取文件到内核态缓存区。
        3、线程收到读取完成指令，经过CPU拷贝数据到用户态缓存区，线程切换到用户态。
        4、线程切换到内核态，经过CPU拷贝数据到Socket内核缓存区，然后，线程切换到用户态。
        5、DMA拷贝Socket内核缓存区的数据到网卡。
        上面的操作，经过了4次线程上下文切换，4次数据的拷贝。
    优化文件传输的性能：
        要想减少上下文切换到次数，就要减少系统调用的次数。避开用户缓冲区。
        具体实现使用:
            MemoryMappedFile：映射内存文件，不直接读取。
            sendfile：直接通过内核态发送文件。

## IO多路复用epoll

    多路复用的目的：
        线程可以通过一个系统调用函数从内核中获取多个事件。
        I/O 多路复用允许一个线程同时监视多个文件描述符（如 socket），当任何一个文件描述符有事件发生时（如可读、可写），系统会通知应用程序。这种方式减少了线程的数量，从而降低了系统开销。在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。
    Linux 下有三种提供 I/O 多路复用的 API，分别是：select、poll、epoll。
        select 和 poll 并没有本质区别
            它们内部都是使用「线性结构」来存储进程关注的 Socket 集合。在使用的时候，首先需要把关注的 Socket 集合通过 select/poll 系统调用从用户态拷贝到内核态，然后由内核检测事件，当有网络事件产生时，内核需要遍历进程关注 Socket 集合，找到对应的 Socket，并设置其状态为可读/可写，然后把整个 Socket 集合从内核态拷贝到用户态，用户态还要继续遍历整个 Socket 集合找到可读/可写的 Socket，然后对其处理。
        epoll
            1、epoll 在内核里使用「红黑树」来关注进程所有待检测的 Socket，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)，通过对这棵黑红树的管理，不需要像 select/poll 在每次操作时都传入整个 Socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配。
            2、epoll 使用事件驱动的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 Socket 集合传递给应用程序，不需要像 select/poll 那样轮询扫描整个集合（包含有和无事件的 Socket ），大大提高了检测的效率。

## 一致性哈希算法

    目的是为了负载均衡。
    假设：
        1、我们会有最多有1000个服务器进行负载均衡。
        2、现在有个环，有2^32，平均的分布在一个环上，叫做哈希环。
    实现：
        1、一个真实服务器设置1000个虚拟节点值，这些虚拟节点哈希值2^32后平均的分布在哈希环上。
        2、增加一个真实服务器，同样按照第一步操作。但是其虚拟节点哈希值在上一个的中间。这样可以保证请求基本平均的落在了服务器上。
        3、请求哈希后，顺时针取第一个服务器去请求。
    解决的问题：
        使用普通的哈希，在增加、移除服务器的时候，请求全部都乱了。通过这个，只会影响顺时针的下一个服务器。

## TCP

    1、TCP报文的主要组成
        源端口号和目标端口号
            确认数据应该发给哪个应用
        序号
            这个是为了解决包乱序的问题。
        确认号
            目的是确认发出去对方是否有收到。如果没有收到就应该重新发送，直到送达，这个是为了解决丢包的问题。
        状态位
            例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。
        窗口大小
            TCP 要做流量控制，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。
        数据
    2、三次握手，确保双方都有发起和接受的能力。
        第一次，客户端发起请求SYN
        第二次，服务器ACK客户端的请求SYN，并对客户端发起请求SYN
        第三次，客户端ACK服务器的请求SYN

## IP

    1、IP报文的主要组成
        协议
            TCP、UDP等
        源地址IP 和 目标地址IP
        
## MAC头部

    只用于点到点传输。广域网中，MAC头部的作用就是将包送达路由器。
    1、MAC头部的主要组成
        发送方 MAC 地址和接收方目标 MAC 地址
        协议类型
        0800 ： IP 协议
        0806 ： ARP 协议
    2、如何知道目标MAC地址，通过ARP协议，询问路由器，路由器广播询问设备得到。

## HTTP请求

    一个HTTP请求由：MAC头部+IP报文+TCP报文+HTTP报文组成。

## IP请求的本质

    就是通过IP寻找MAC，然后通过MAC传输数据的过程。
        局域网
            通过ARP协议，询问路由器，路由器广播询问设备得到。
        广域网
            1、通过ARP协议，询问路由器，路由器广播没有获取到MAC，则使用自己的MAC，数据发给了路由器。
            2、路由器则在路由器中寻找负责这个IP的路由器，这里的算法非常复杂，没有深入。然后一步步把数据转发到目标路由器。
            3、目标路由器获得目标IP的MAC，最后把数据发给目标IP。

## TCP/IP 网络模型

    应用层，负责向用户提供一组应用程序，比如 HTTP、DNS、FTP 等;
    传输层，负责端到端的通信，比如 TCP、UDP 等；
    网络层，负责网络包的封装、分片、路由、转发，比如 IP、ICMP 等；
    网络接口层，负责网络包在物理网络中的传输，比如网络包的封帧、 MAC 寻址、差错检测，以及通过网卡传输网络帧等

## HTTP状态码

    1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。
    2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。
    3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。
    4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。
    5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。

## HTTP常用字段

    Host: 客户端发送请求时，用来指定服务器的域名。
    Content-Length：表明本次回应的数据长度。
    Connection：Keep-Alive，开启后，连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个连接，一直持续到客户端或服务器端提出断开连接。
    Content-Type:数据是什么格式
    Accept: 声明自己可以接受哪些数据格式。
    Content-Encoding:数据使用了什么压缩格式
    Accept-Encoding:接受哪些压缩方法
    Cache-Control， 是一个相对时间,用来控制浏览器本地缓存。
    Expires，是一个绝对时间,用来控制浏览器本地缓存。

## HTTPS

    HTTPS的作用：
        1、加密内容，通过混合加密。
        2、防止篡改，通过摘要算法。
        3、防止冒充，通过数字证书是权威机构CA发放。
    非对称加密简要描述：
        1、公钥加密，私钥解密。
            这个目的是为了保证内容传输的安全，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；
        2、私钥加密，公钥解密。
            这个目的是为了保证消息不会被冒充，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。
    HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式：
        在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。
        在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。
    摘要算法
        1、对内容进行哈希，获得哈希值，通过私钥加密，获得数字签名，内容+数字签名发给浏览器。
        2、浏览器对内容进行哈希，使用公钥解密数字签名，进行对比，如果相同，这说明内容是通过匹配的私钥加密的，没有被篡改。
    采用「混合加密」的方式的原因：
        对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
        非对称密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。
    HTTPS防止冒充的流程：
        1、服务器把服务器公钥发给我CA机构
        2、CA机构通过自己的私钥，将服务器公钥数字签名，获得数字证书，包含：数字签名、服务器公钥,并把数字证书颁发给服务器。
        3、浏览器内置了获取CA公钥的方法，并拿到了CA的公钥。
        4、客户端拿到服务器的数字证书，使用CA公钥确认数字签名的准确性，确认服务器的数字证书的真实性，并获得服务器公钥。（确认真实性办法见：摘要算法）
        5、使用服务器公钥对内容进行加密。
        6、服务器使用私钥对内容进行解密。
    
## HTTPS RSA建立连接

    1、三次握手（客户端SYNC-服务器SYNC+ACK-客户端ACK）
    2、客户端发送：客户端产生的随机数、支持的TLS版本、支持的加密方式列表
    3、服务器发送：服务器产生的随机数、服务器数字证书、支持的加密方式列表
        确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。
    4、客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：
        一、一个随机数（pre-master key）。该随机数会被服务器公钥加密。
        二、加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
        三、客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。
    5、服务器收到到后，根据客户端随机数、服务器随机数、pre-master key，通过私钥加密，得到会话秘钥。然后，向客户端发送最后的信息：
        一、加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
        二、服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。
    至此，整个 TLS 的握手阶段全部结束。
    这里的重点是：
        服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成相同的本次通信的「会话秘钥」。

## HTTP/1.1优化方案

    1、